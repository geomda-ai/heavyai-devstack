services:
  heavydb:
    env_file: .env
    container_name: ${HEAVYDB_SERVICE_NAME}
    image: ${CONTAINER}
    restart: unless-stopped
    ipc: shareable
    entrypoint: /bin/bash -c '/opt/heavyai/bin/heavydb --config ${HEAVYDB_CONFIG_FILE}'
    volumes:
    - /var/lib/heavyai:/var/lib/heavyai
    networks:
    - heavy-network
    ports:
    - "${HEAVYDB_PORT}:${HEAVYDB_PORT}"
    - "${HEAVYDB_BACKEND_PORT}:${HEAVYDB_BACKEND_PORT}"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

  immerse:
    env_file: .env
    container_name: ${IMMERSE_SERVICE_NAME}
    image: ${CONTAINER}
    restart: unless-stopped
    ipc: shareable
    entrypoint: /bin/bash -c '/opt/heavyai/bin/heavy_web_server --config ${HEAVY_IMMERSE_CONFIG_FILE}'
    volumes:
    - /var/lib/heavyai:/var/lib/heavyai
    networks:
    - heavy-network
    ports:
    - "${IMMERSE_PORT}:${IMMERSE_PORT}"

  iq:
    env_file: .env
    container_name: ${IQ_SERVICE_NAME}
    image: ${CONTAINER}
    restart: unless-stopped
    ipc: shareable
    environment:
    - CONFIG_FILE=${HEAVY_IQ_CONFIG_FILE}
    - MAPD_DATA=${HEAVY_IQ_LOCATION}
    - MAPD_HEAVYIQ_PORT=${HEAVYIQ_PORT}
    entrypoint: /bin/bash -c '/opt/heavyai/scripts/ee/start_heavyiq.sh && tail -f /dev/null'
    volumes:
    - /var/lib/heavyai:/var/lib/heavyai
    networks:
    - heavy-network
    ports:
    - "${HEAVYIQ_PORT}:${HEAVYIQ_PORT}"

networks:
  heavy-network:
    name: heavy-network
